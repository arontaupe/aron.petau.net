---
title:  Chatbot
date:   2022-03-01 14:39:27 +0100
author: Aron Petau
excerpt: A speech-controlled meditation assistant and sentiment tracker
header:
  overlay_image: "https://cloud.google.com/dialogflow/es/docs/images/fulfillment-flow.svg"
  teaser: "https://cloud.google.com/dialogflow/es/docs/images/fulfillment-flow.svg"
  credit: "Google Dialogflow Documentation"
tags:
  - nlp
  - nlu
  - google assistant
  - python
  - speech interface
  - data viz
  - work
  - sql
  - voice assistant
  - meditation
  - chatbot
  - google dialogflow
  - google cloud
  - university of osnabrück
created: 2023-07-27T00:00:19+02:00
last_modified_at: 2023-10-01T20:15:51+02:00
---
## Guru to Go: a speech-controlled meditation assistant and sentiment tracker

{% include video id="R73vAH37TC0" provider="youtube" %}

Here, you see a Demo video of a voice-controlled meditation assistant that we worked on in the course "Conversational Agents and speech interfaces"
[Course Description](https://w3o.ikw.uni-osnabrueck.de/scheinmaker/export/details/76/
){: .btn .btn--large}

The central goal of the entire project was to make the Assistant be entirely speech controlled, such that the phone needn't be touched while immersing yourself in meditation.

The Chatbot was built in Google Dialogflow, a natural language understanding engine that can interpret free text input and identify entities and intents within it,
We wrote a custom python backend to then use these evaluated intents and compute individualized responses.

The resulting application runs in Google Assistant and can adaptively deliver meditations, visualize sentiment history and comprehensively inform about meditation practices. Sadly, we used beta functionality from the older "Google Assistant" Framework, which got rebranded months after by Google into "Actions on Google" and changed core functionality requiring extensive migration that neither Chris, my partner in this project, nor I found time to do.

Nevertheless, the whole Chatbot functioned as a meditation player and was able to graph and store recorded sentiments over time for each user.

Attached below you can also find our final report with details on the programming and thought process.

[Read the full report](https://acrobat.adobe.com/link/track?uri=urn:aaid:scds:US:23118565-e24e-4586-b0e0-c0ef7550a067
){: .btn .btn--large}

[Look at the Project on GitHub](https://github.com/cstenkamp/medibot_pythonbackend
){: .btn .btn--large}

After this being my first dip into using the Google Framework for the creation of a speech assistant and encountering many problems along the way that partly found their way also into the final report, now I managed to utilize these explorations and am currently working to create [Ällei](/allei/), another chatbot with a different focus, which is not realized within Actions on google, but will rather be getting its own react app on a website.
{: .notice}
